{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bc69b59",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "36ad8ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "from prettytable import PrettyTable\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers import BatchNormalization, Dropout\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847437ac",
   "metadata": {},
   "source": [
    "## Loading Moment Invariants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fa54cdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the generated training moment\n",
    "train_df = pd.read_csv('C:/Users/noqui/Desktop/FYP\\Work_Folder_Testing/output/moment/Cassava//100/Cassava_Train_512.csv')\n",
    "\n",
    "# reading the generated testing moment\n",
    "test_df = pd.read_csv('C:/Users/noqui/Desktop/FYP\\Work_Folder_Testing/output/moment/Cassava/100/Cassava_Test_512.csv')\n",
    "\n",
    "train_df.reset_index(drop = True, inplace = True)\n",
    "train_df = train_df.dropna()\n",
    "\n",
    "test_df.reset_index(drop = True, inplace = True)\n",
    "test_df = test_df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c6850f",
   "metadata": {},
   "source": [
    "### Preparing the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "62356477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14980, 227)\n",
      "(6417, 227)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Inm[0,2]</th>\n",
       "      <th>Inm[2,0]</th>\n",
       "      <th>Inm[0,3]</th>\n",
       "      <th>Inm[1,2]</th>\n",
       "      <th>Inm[2,1]</th>\n",
       "      <th>Inm[3,0]</th>\n",
       "      <th>Inm[0,4]</th>\n",
       "      <th>Inm[1,3]</th>\n",
       "      <th>Inm[2,2]</th>\n",
       "      <th>Inm[3,1]</th>\n",
       "      <th>...</th>\n",
       "      <th>Inm[11,9]</th>\n",
       "      <th>Inm[12,8]</th>\n",
       "      <th>Inm[13,7]</th>\n",
       "      <th>Inm[14,6]</th>\n",
       "      <th>Inm[15,5]</th>\n",
       "      <th>Inm[16,4]</th>\n",
       "      <th>Inm[17,3]</th>\n",
       "      <th>Inm[18,2]</th>\n",
       "      <th>Inm[19,1]</th>\n",
       "      <th>Inm[20,0]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.080198</td>\n",
       "      <td>0.097889</td>\n",
       "      <td>0.009538</td>\n",
       "      <td>0.600463</td>\n",
       "      <td>0.382801</td>\n",
       "      <td>0.560823</td>\n",
       "      <td>0.863587</td>\n",
       "      <td>0.471308</td>\n",
       "      <td>0.899099</td>\n",
       "      <td>0.382024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.458812</td>\n",
       "      <td>0.483395</td>\n",
       "      <td>0.624666</td>\n",
       "      <td>0.394148</td>\n",
       "      <td>0.475241</td>\n",
       "      <td>0.436230</td>\n",
       "      <td>0.369309</td>\n",
       "      <td>0.631207</td>\n",
       "      <td>0.415657</td>\n",
       "      <td>0.709320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.300600</td>\n",
       "      <td>0.371140</td>\n",
       "      <td>0.086635</td>\n",
       "      <td>0.685474</td>\n",
       "      <td>0.413572</td>\n",
       "      <td>0.727353</td>\n",
       "      <td>0.561264</td>\n",
       "      <td>0.680328</td>\n",
       "      <td>0.619227</td>\n",
       "      <td>0.136749</td>\n",
       "      <td>...</td>\n",
       "      <td>0.477605</td>\n",
       "      <td>0.513108</td>\n",
       "      <td>0.683432</td>\n",
       "      <td>0.549288</td>\n",
       "      <td>0.564549</td>\n",
       "      <td>0.478880</td>\n",
       "      <td>0.525941</td>\n",
       "      <td>0.491742</td>\n",
       "      <td>0.643794</td>\n",
       "      <td>0.546375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.116834</td>\n",
       "      <td>0.123254</td>\n",
       "      <td>0.020849</td>\n",
       "      <td>0.609138</td>\n",
       "      <td>0.366738</td>\n",
       "      <td>0.565231</td>\n",
       "      <td>0.814772</td>\n",
       "      <td>0.433776</td>\n",
       "      <td>0.857001</td>\n",
       "      <td>0.420067</td>\n",
       "      <td>...</td>\n",
       "      <td>0.385411</td>\n",
       "      <td>0.445322</td>\n",
       "      <td>0.506545</td>\n",
       "      <td>0.573518</td>\n",
       "      <td>0.415377</td>\n",
       "      <td>0.606877</td>\n",
       "      <td>0.367130</td>\n",
       "      <td>0.545870</td>\n",
       "      <td>0.437492</td>\n",
       "      <td>0.491139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.157244</td>\n",
       "      <td>0.164603</td>\n",
       "      <td>0.033927</td>\n",
       "      <td>0.638301</td>\n",
       "      <td>0.366185</td>\n",
       "      <td>0.545039</td>\n",
       "      <td>0.770974</td>\n",
       "      <td>0.492855</td>\n",
       "      <td>0.799868</td>\n",
       "      <td>0.347873</td>\n",
       "      <td>...</td>\n",
       "      <td>0.421950</td>\n",
       "      <td>0.522118</td>\n",
       "      <td>0.561011</td>\n",
       "      <td>0.370241</td>\n",
       "      <td>0.492356</td>\n",
       "      <td>0.297456</td>\n",
       "      <td>0.460087</td>\n",
       "      <td>0.426757</td>\n",
       "      <td>0.531547</td>\n",
       "      <td>0.489821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.581968</td>\n",
       "      <td>0.690743</td>\n",
       "      <td>0.125258</td>\n",
       "      <td>0.809572</td>\n",
       "      <td>0.498387</td>\n",
       "      <td>0.844144</td>\n",
       "      <td>0.304441</td>\n",
       "      <td>0.341879</td>\n",
       "      <td>0.278852</td>\n",
       "      <td>0.650447</td>\n",
       "      <td>...</td>\n",
       "      <td>0.282702</td>\n",
       "      <td>0.684930</td>\n",
       "      <td>0.515188</td>\n",
       "      <td>0.539361</td>\n",
       "      <td>0.664117</td>\n",
       "      <td>0.375388</td>\n",
       "      <td>0.643017</td>\n",
       "      <td>0.419981</td>\n",
       "      <td>0.564220</td>\n",
       "      <td>0.445665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14975</th>\n",
       "      <td>0.180040</td>\n",
       "      <td>0.182701</td>\n",
       "      <td>0.034091</td>\n",
       "      <td>0.653720</td>\n",
       "      <td>0.395388</td>\n",
       "      <td>0.618273</td>\n",
       "      <td>0.732266</td>\n",
       "      <td>0.552341</td>\n",
       "      <td>0.775782</td>\n",
       "      <td>0.287869</td>\n",
       "      <td>...</td>\n",
       "      <td>0.467597</td>\n",
       "      <td>0.568799</td>\n",
       "      <td>0.558748</td>\n",
       "      <td>0.483072</td>\n",
       "      <td>0.424700</td>\n",
       "      <td>0.414590</td>\n",
       "      <td>0.366945</td>\n",
       "      <td>0.462520</td>\n",
       "      <td>0.440918</td>\n",
       "      <td>0.492146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14976</th>\n",
       "      <td>0.246096</td>\n",
       "      <td>0.239353</td>\n",
       "      <td>0.006931</td>\n",
       "      <td>0.560176</td>\n",
       "      <td>0.411945</td>\n",
       "      <td>0.565190</td>\n",
       "      <td>0.624444</td>\n",
       "      <td>0.581166</td>\n",
       "      <td>0.710529</td>\n",
       "      <td>0.244915</td>\n",
       "      <td>...</td>\n",
       "      <td>0.511178</td>\n",
       "      <td>0.631692</td>\n",
       "      <td>0.704645</td>\n",
       "      <td>0.685684</td>\n",
       "      <td>0.592208</td>\n",
       "      <td>0.644088</td>\n",
       "      <td>0.545171</td>\n",
       "      <td>0.549210</td>\n",
       "      <td>0.653999</td>\n",
       "      <td>0.489206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14977</th>\n",
       "      <td>0.327762</td>\n",
       "      <td>0.321838</td>\n",
       "      <td>0.170592</td>\n",
       "      <td>0.586232</td>\n",
       "      <td>0.332471</td>\n",
       "      <td>0.592243</td>\n",
       "      <td>0.569727</td>\n",
       "      <td>0.471944</td>\n",
       "      <td>0.602428</td>\n",
       "      <td>0.402386</td>\n",
       "      <td>...</td>\n",
       "      <td>0.366034</td>\n",
       "      <td>0.758119</td>\n",
       "      <td>0.493416</td>\n",
       "      <td>0.506975</td>\n",
       "      <td>0.478493</td>\n",
       "      <td>0.479247</td>\n",
       "      <td>0.481144</td>\n",
       "      <td>0.651477</td>\n",
       "      <td>0.562304</td>\n",
       "      <td>0.681890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14978</th>\n",
       "      <td>0.109982</td>\n",
       "      <td>0.133604</td>\n",
       "      <td>0.024535</td>\n",
       "      <td>0.570839</td>\n",
       "      <td>0.387718</td>\n",
       "      <td>0.552084</td>\n",
       "      <td>0.820546</td>\n",
       "      <td>0.547006</td>\n",
       "      <td>0.858603</td>\n",
       "      <td>0.292849</td>\n",
       "      <td>...</td>\n",
       "      <td>0.396339</td>\n",
       "      <td>0.457801</td>\n",
       "      <td>0.487137</td>\n",
       "      <td>0.534057</td>\n",
       "      <td>0.531898</td>\n",
       "      <td>0.567873</td>\n",
       "      <td>0.601905</td>\n",
       "      <td>0.593012</td>\n",
       "      <td>0.704146</td>\n",
       "      <td>0.594058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14979</th>\n",
       "      <td>0.135654</td>\n",
       "      <td>0.138654</td>\n",
       "      <td>0.019443</td>\n",
       "      <td>0.573486</td>\n",
       "      <td>0.384146</td>\n",
       "      <td>0.576222</td>\n",
       "      <td>0.790480</td>\n",
       "      <td>0.433584</td>\n",
       "      <td>0.831660</td>\n",
       "      <td>0.419315</td>\n",
       "      <td>...</td>\n",
       "      <td>0.402766</td>\n",
       "      <td>0.491574</td>\n",
       "      <td>0.530322</td>\n",
       "      <td>0.524632</td>\n",
       "      <td>0.506255</td>\n",
       "      <td>0.451556</td>\n",
       "      <td>0.506233</td>\n",
       "      <td>0.385442</td>\n",
       "      <td>0.582814</td>\n",
       "      <td>0.343290</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14980 rows × 227 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Inm[0,2]  Inm[2,0]  Inm[0,3]  Inm[1,2]  Inm[2,1]  Inm[3,0]  Inm[0,4]  \\\n",
       "0      0.080198  0.097889  0.009538  0.600463  0.382801  0.560823  0.863587   \n",
       "1      0.300600  0.371140  0.086635  0.685474  0.413572  0.727353  0.561264   \n",
       "2      0.116834  0.123254  0.020849  0.609138  0.366738  0.565231  0.814772   \n",
       "3      0.157244  0.164603  0.033927  0.638301  0.366185  0.545039  0.770974   \n",
       "4      0.581968  0.690743  0.125258  0.809572  0.498387  0.844144  0.304441   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "14975  0.180040  0.182701  0.034091  0.653720  0.395388  0.618273  0.732266   \n",
       "14976  0.246096  0.239353  0.006931  0.560176  0.411945  0.565190  0.624444   \n",
       "14977  0.327762  0.321838  0.170592  0.586232  0.332471  0.592243  0.569727   \n",
       "14978  0.109982  0.133604  0.024535  0.570839  0.387718  0.552084  0.820546   \n",
       "14979  0.135654  0.138654  0.019443  0.573486  0.384146  0.576222  0.790480   \n",
       "\n",
       "       Inm[1,3]  Inm[2,2]  Inm[3,1]  ...  Inm[11,9]  Inm[12,8]  Inm[13,7]  \\\n",
       "0      0.471308  0.899099  0.382024  ...   0.458812   0.483395   0.624666   \n",
       "1      0.680328  0.619227  0.136749  ...   0.477605   0.513108   0.683432   \n",
       "2      0.433776  0.857001  0.420067  ...   0.385411   0.445322   0.506545   \n",
       "3      0.492855  0.799868  0.347873  ...   0.421950   0.522118   0.561011   \n",
       "4      0.341879  0.278852  0.650447  ...   0.282702   0.684930   0.515188   \n",
       "...         ...       ...       ...  ...        ...        ...        ...   \n",
       "14975  0.552341  0.775782  0.287869  ...   0.467597   0.568799   0.558748   \n",
       "14976  0.581166  0.710529  0.244915  ...   0.511178   0.631692   0.704645   \n",
       "14977  0.471944  0.602428  0.402386  ...   0.366034   0.758119   0.493416   \n",
       "14978  0.547006  0.858603  0.292849  ...   0.396339   0.457801   0.487137   \n",
       "14979  0.433584  0.831660  0.419315  ...   0.402766   0.491574   0.530322   \n",
       "\n",
       "       Inm[14,6]  Inm[15,5]  Inm[16,4]  Inm[17,3]  Inm[18,2]  Inm[19,1]  \\\n",
       "0       0.394148   0.475241   0.436230   0.369309   0.631207   0.415657   \n",
       "1       0.549288   0.564549   0.478880   0.525941   0.491742   0.643794   \n",
       "2       0.573518   0.415377   0.606877   0.367130   0.545870   0.437492   \n",
       "3       0.370241   0.492356   0.297456   0.460087   0.426757   0.531547   \n",
       "4       0.539361   0.664117   0.375388   0.643017   0.419981   0.564220   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "14975   0.483072   0.424700   0.414590   0.366945   0.462520   0.440918   \n",
       "14976   0.685684   0.592208   0.644088   0.545171   0.549210   0.653999   \n",
       "14977   0.506975   0.478493   0.479247   0.481144   0.651477   0.562304   \n",
       "14978   0.534057   0.531898   0.567873   0.601905   0.593012   0.704146   \n",
       "14979   0.524632   0.506255   0.451556   0.506233   0.385442   0.582814   \n",
       "\n",
       "       Inm[20,0]  \n",
       "0       0.709320  \n",
       "1       0.546375  \n",
       "2       0.491139  \n",
       "3       0.489821  \n",
       "4       0.445665  \n",
       "...          ...  \n",
       "14975   0.492146  \n",
       "14976   0.489206  \n",
       "14977   0.681890  \n",
       "14978   0.594058  \n",
       "14979   0.343290  \n",
       "\n",
       "[14980 rows x 227 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Inm[0,2]</th>\n",
       "      <th>Inm[2,0]</th>\n",
       "      <th>Inm[0,3]</th>\n",
       "      <th>Inm[1,2]</th>\n",
       "      <th>Inm[2,1]</th>\n",
       "      <th>Inm[3,0]</th>\n",
       "      <th>Inm[0,4]</th>\n",
       "      <th>Inm[1,3]</th>\n",
       "      <th>Inm[2,2]</th>\n",
       "      <th>Inm[3,1]</th>\n",
       "      <th>...</th>\n",
       "      <th>Inm[11,9]</th>\n",
       "      <th>Inm[12,8]</th>\n",
       "      <th>Inm[13,7]</th>\n",
       "      <th>Inm[14,6]</th>\n",
       "      <th>Inm[15,5]</th>\n",
       "      <th>Inm[16,4]</th>\n",
       "      <th>Inm[17,3]</th>\n",
       "      <th>Inm[18,2]</th>\n",
       "      <th>Inm[19,1]</th>\n",
       "      <th>Inm[20,0]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.080198</td>\n",
       "      <td>0.097889</td>\n",
       "      <td>0.009538</td>\n",
       "      <td>0.600463</td>\n",
       "      <td>0.382801</td>\n",
       "      <td>0.560823</td>\n",
       "      <td>0.863587</td>\n",
       "      <td>0.471308</td>\n",
       "      <td>0.899099</td>\n",
       "      <td>0.382024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.458812</td>\n",
       "      <td>0.483395</td>\n",
       "      <td>0.624666</td>\n",
       "      <td>0.394148</td>\n",
       "      <td>0.475241</td>\n",
       "      <td>0.436230</td>\n",
       "      <td>0.369309</td>\n",
       "      <td>0.631207</td>\n",
       "      <td>0.415657</td>\n",
       "      <td>0.709320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.300600</td>\n",
       "      <td>0.371140</td>\n",
       "      <td>0.086635</td>\n",
       "      <td>0.685474</td>\n",
       "      <td>0.413572</td>\n",
       "      <td>0.727353</td>\n",
       "      <td>0.561264</td>\n",
       "      <td>0.680328</td>\n",
       "      <td>0.619227</td>\n",
       "      <td>0.136749</td>\n",
       "      <td>...</td>\n",
       "      <td>0.477605</td>\n",
       "      <td>0.513108</td>\n",
       "      <td>0.683432</td>\n",
       "      <td>0.549288</td>\n",
       "      <td>0.564549</td>\n",
       "      <td>0.478880</td>\n",
       "      <td>0.525941</td>\n",
       "      <td>0.491742</td>\n",
       "      <td>0.643794</td>\n",
       "      <td>0.546375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.116834</td>\n",
       "      <td>0.123254</td>\n",
       "      <td>0.020849</td>\n",
       "      <td>0.609138</td>\n",
       "      <td>0.366738</td>\n",
       "      <td>0.565231</td>\n",
       "      <td>0.814772</td>\n",
       "      <td>0.433776</td>\n",
       "      <td>0.857001</td>\n",
       "      <td>0.420067</td>\n",
       "      <td>...</td>\n",
       "      <td>0.385411</td>\n",
       "      <td>0.445322</td>\n",
       "      <td>0.506545</td>\n",
       "      <td>0.573518</td>\n",
       "      <td>0.415377</td>\n",
       "      <td>0.606877</td>\n",
       "      <td>0.367130</td>\n",
       "      <td>0.545870</td>\n",
       "      <td>0.437492</td>\n",
       "      <td>0.491139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.157244</td>\n",
       "      <td>0.164603</td>\n",
       "      <td>0.033927</td>\n",
       "      <td>0.638301</td>\n",
       "      <td>0.366185</td>\n",
       "      <td>0.545039</td>\n",
       "      <td>0.770974</td>\n",
       "      <td>0.492855</td>\n",
       "      <td>0.799868</td>\n",
       "      <td>0.347873</td>\n",
       "      <td>...</td>\n",
       "      <td>0.421950</td>\n",
       "      <td>0.522118</td>\n",
       "      <td>0.561011</td>\n",
       "      <td>0.370241</td>\n",
       "      <td>0.492356</td>\n",
       "      <td>0.297456</td>\n",
       "      <td>0.460087</td>\n",
       "      <td>0.426757</td>\n",
       "      <td>0.531547</td>\n",
       "      <td>0.489821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.581968</td>\n",
       "      <td>0.690743</td>\n",
       "      <td>0.125258</td>\n",
       "      <td>0.809572</td>\n",
       "      <td>0.498387</td>\n",
       "      <td>0.844144</td>\n",
       "      <td>0.304441</td>\n",
       "      <td>0.341879</td>\n",
       "      <td>0.278852</td>\n",
       "      <td>0.650447</td>\n",
       "      <td>...</td>\n",
       "      <td>0.282702</td>\n",
       "      <td>0.684930</td>\n",
       "      <td>0.515188</td>\n",
       "      <td>0.539361</td>\n",
       "      <td>0.664117</td>\n",
       "      <td>0.375388</td>\n",
       "      <td>0.643017</td>\n",
       "      <td>0.419981</td>\n",
       "      <td>0.564220</td>\n",
       "      <td>0.445665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14975</th>\n",
       "      <td>0.180040</td>\n",
       "      <td>0.182701</td>\n",
       "      <td>0.034091</td>\n",
       "      <td>0.653720</td>\n",
       "      <td>0.395388</td>\n",
       "      <td>0.618273</td>\n",
       "      <td>0.732266</td>\n",
       "      <td>0.552341</td>\n",
       "      <td>0.775782</td>\n",
       "      <td>0.287869</td>\n",
       "      <td>...</td>\n",
       "      <td>0.467597</td>\n",
       "      <td>0.568799</td>\n",
       "      <td>0.558748</td>\n",
       "      <td>0.483072</td>\n",
       "      <td>0.424700</td>\n",
       "      <td>0.414590</td>\n",
       "      <td>0.366945</td>\n",
       "      <td>0.462520</td>\n",
       "      <td>0.440918</td>\n",
       "      <td>0.492146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14976</th>\n",
       "      <td>0.246096</td>\n",
       "      <td>0.239353</td>\n",
       "      <td>0.006931</td>\n",
       "      <td>0.560176</td>\n",
       "      <td>0.411945</td>\n",
       "      <td>0.565190</td>\n",
       "      <td>0.624444</td>\n",
       "      <td>0.581166</td>\n",
       "      <td>0.710529</td>\n",
       "      <td>0.244915</td>\n",
       "      <td>...</td>\n",
       "      <td>0.511178</td>\n",
       "      <td>0.631692</td>\n",
       "      <td>0.704645</td>\n",
       "      <td>0.685684</td>\n",
       "      <td>0.592208</td>\n",
       "      <td>0.644088</td>\n",
       "      <td>0.545171</td>\n",
       "      <td>0.549210</td>\n",
       "      <td>0.653999</td>\n",
       "      <td>0.489206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14977</th>\n",
       "      <td>0.327762</td>\n",
       "      <td>0.321838</td>\n",
       "      <td>0.170592</td>\n",
       "      <td>0.586232</td>\n",
       "      <td>0.332471</td>\n",
       "      <td>0.592243</td>\n",
       "      <td>0.569727</td>\n",
       "      <td>0.471944</td>\n",
       "      <td>0.602428</td>\n",
       "      <td>0.402386</td>\n",
       "      <td>...</td>\n",
       "      <td>0.366034</td>\n",
       "      <td>0.758119</td>\n",
       "      <td>0.493416</td>\n",
       "      <td>0.506975</td>\n",
       "      <td>0.478493</td>\n",
       "      <td>0.479247</td>\n",
       "      <td>0.481144</td>\n",
       "      <td>0.651477</td>\n",
       "      <td>0.562304</td>\n",
       "      <td>0.681890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14978</th>\n",
       "      <td>0.109982</td>\n",
       "      <td>0.133604</td>\n",
       "      <td>0.024535</td>\n",
       "      <td>0.570839</td>\n",
       "      <td>0.387718</td>\n",
       "      <td>0.552084</td>\n",
       "      <td>0.820546</td>\n",
       "      <td>0.547006</td>\n",
       "      <td>0.858603</td>\n",
       "      <td>0.292849</td>\n",
       "      <td>...</td>\n",
       "      <td>0.396339</td>\n",
       "      <td>0.457801</td>\n",
       "      <td>0.487137</td>\n",
       "      <td>0.534057</td>\n",
       "      <td>0.531898</td>\n",
       "      <td>0.567873</td>\n",
       "      <td>0.601905</td>\n",
       "      <td>0.593012</td>\n",
       "      <td>0.704146</td>\n",
       "      <td>0.594058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14979</th>\n",
       "      <td>0.135654</td>\n",
       "      <td>0.138654</td>\n",
       "      <td>0.019443</td>\n",
       "      <td>0.573486</td>\n",
       "      <td>0.384146</td>\n",
       "      <td>0.576222</td>\n",
       "      <td>0.790480</td>\n",
       "      <td>0.433584</td>\n",
       "      <td>0.831660</td>\n",
       "      <td>0.419315</td>\n",
       "      <td>...</td>\n",
       "      <td>0.402766</td>\n",
       "      <td>0.491574</td>\n",
       "      <td>0.530322</td>\n",
       "      <td>0.524632</td>\n",
       "      <td>0.506255</td>\n",
       "      <td>0.451556</td>\n",
       "      <td>0.506233</td>\n",
       "      <td>0.385442</td>\n",
       "      <td>0.582814</td>\n",
       "      <td>0.343290</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14980 rows × 227 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Inm[0,2]  Inm[2,0]  Inm[0,3]  Inm[1,2]  Inm[2,1]  Inm[3,0]  Inm[0,4]  \\\n",
       "0      0.080198  0.097889  0.009538  0.600463  0.382801  0.560823  0.863587   \n",
       "1      0.300600  0.371140  0.086635  0.685474  0.413572  0.727353  0.561264   \n",
       "2      0.116834  0.123254  0.020849  0.609138  0.366738  0.565231  0.814772   \n",
       "3      0.157244  0.164603  0.033927  0.638301  0.366185  0.545039  0.770974   \n",
       "4      0.581968  0.690743  0.125258  0.809572  0.498387  0.844144  0.304441   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "14975  0.180040  0.182701  0.034091  0.653720  0.395388  0.618273  0.732266   \n",
       "14976  0.246096  0.239353  0.006931  0.560176  0.411945  0.565190  0.624444   \n",
       "14977  0.327762  0.321838  0.170592  0.586232  0.332471  0.592243  0.569727   \n",
       "14978  0.109982  0.133604  0.024535  0.570839  0.387718  0.552084  0.820546   \n",
       "14979  0.135654  0.138654  0.019443  0.573486  0.384146  0.576222  0.790480   \n",
       "\n",
       "       Inm[1,3]  Inm[2,2]  Inm[3,1]  ...  Inm[11,9]  Inm[12,8]  Inm[13,7]  \\\n",
       "0      0.471308  0.899099  0.382024  ...   0.458812   0.483395   0.624666   \n",
       "1      0.680328  0.619227  0.136749  ...   0.477605   0.513108   0.683432   \n",
       "2      0.433776  0.857001  0.420067  ...   0.385411   0.445322   0.506545   \n",
       "3      0.492855  0.799868  0.347873  ...   0.421950   0.522118   0.561011   \n",
       "4      0.341879  0.278852  0.650447  ...   0.282702   0.684930   0.515188   \n",
       "...         ...       ...       ...  ...        ...        ...        ...   \n",
       "14975  0.552341  0.775782  0.287869  ...   0.467597   0.568799   0.558748   \n",
       "14976  0.581166  0.710529  0.244915  ...   0.511178   0.631692   0.704645   \n",
       "14977  0.471944  0.602428  0.402386  ...   0.366034   0.758119   0.493416   \n",
       "14978  0.547006  0.858603  0.292849  ...   0.396339   0.457801   0.487137   \n",
       "14979  0.433584  0.831660  0.419315  ...   0.402766   0.491574   0.530322   \n",
       "\n",
       "       Inm[14,6]  Inm[15,5]  Inm[16,4]  Inm[17,3]  Inm[18,2]  Inm[19,1]  \\\n",
       "0       0.394148   0.475241   0.436230   0.369309   0.631207   0.415657   \n",
       "1       0.549288   0.564549   0.478880   0.525941   0.491742   0.643794   \n",
       "2       0.573518   0.415377   0.606877   0.367130   0.545870   0.437492   \n",
       "3       0.370241   0.492356   0.297456   0.460087   0.426757   0.531547   \n",
       "4       0.539361   0.664117   0.375388   0.643017   0.419981   0.564220   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "14975   0.483072   0.424700   0.414590   0.366945   0.462520   0.440918   \n",
       "14976   0.685684   0.592208   0.644088   0.545171   0.549210   0.653999   \n",
       "14977   0.506975   0.478493   0.479247   0.481144   0.651477   0.562304   \n",
       "14978   0.534057   0.531898   0.567873   0.601905   0.593012   0.704146   \n",
       "14979   0.524632   0.506255   0.451556   0.506233   0.385442   0.582814   \n",
       "\n",
       "       Inm[20,0]  \n",
       "0       0.709320  \n",
       "1       0.546375  \n",
       "2       0.491139  \n",
       "3       0.489821  \n",
       "4       0.445665  \n",
       "...          ...  \n",
       "14975   0.492146  \n",
       "14976   0.489206  \n",
       "14977   0.681890  \n",
       "14978   0.594058  \n",
       "14979   0.343290  \n",
       "\n",
       "[14980 rows x 227 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train_df = train_df.sort_values(['label'])\n",
    "X_train_df = X_train_df.drop(['Inm[1,1]'], axis = 1) # drop Inm[1,1]\n",
    "X_test_df = test_df.sort_values(['label'])\n",
    "X_test_df = X_test_df.drop(['Inm[1,1]'], axis = 1) # drop Inm[1,1]\n",
    "\n",
    "# reset index\n",
    "X_train_df.reset_index(inplace = True, drop = True)\n",
    "X_test_df.reset_index(inplace = True, drop = True)\n",
    "\n",
    "data = X_train_df.append([X_test_df])\n",
    "y = data['class']\n",
    "\n",
    "X_train_df = X_train_df.iloc[:,3:230].copy() # excluding (Inm[0,0], Inm[0,1], Inm[1,0])\n",
    "X_test_df = X_test_df.iloc[:,3:230].copy() # excluding (Inm[0,0], Inm[0,1], Inm[1,0])\n",
    "\n",
    "# apply normalization \n",
    "for column in X_train_df.columns:\n",
    "    X_train_df[column] = (X_train_df[column] - X_train_df[column].min()) / (X_train_df[column].max() - X_train_df[column].min()) \n",
    "\n",
    "for column in X_test_df.columns:\n",
    "    X_test_df[column] = (X_test_df[column] - X_test_df[column].min()) / (X_test_df[column].max() - X_test_df[column].min()) \n",
    "\n",
    "print(X_train_df.shape)\n",
    "print(X_test_df.shape)\n",
    "display(X_train_df)\n",
    "display(X_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7c7f038d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21397, 227), (21397,))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X_train_df.append([X_test_df])\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ebb29bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14977, 227) (6420, 227)\n",
      "(14977,) (6420,)\n"
     ]
    }
   ],
   "source": [
    "#Split the data in training set and test set.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 28)\n",
    "    \n",
    "print(X_train.shape, X_test.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1573df3e",
   "metadata": {},
   "source": [
    "### Selecting Moments up to nth Order "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "41f0b228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "Train (14977, 17)\n",
      "Test (6420, 17)\n",
      "\n",
      "62\n",
      "Train (14977, 62)\n",
      "Test (6420, 62)\n",
      "\n",
      "132\n",
      "Train (14977, 132)\n",
      "Test (6420, 132)\n",
      "\n",
      "227\n",
      "Train (14977, 227)\n",
      "Test (6420, 227)\n"
     ]
    }
   ],
   "source": [
    "# get the number of columns to slice up to n order\n",
    "def getOrderIndex(n_order):\n",
    "    return int((n_order + 1) * (n_order + 2) / 2)\n",
    "\n",
    "# ordPQ\n",
    "n_order = 5\n",
    "number_of_index = getOrderIndex(n_order) - 4\n",
    "print(number_of_index)\n",
    "\n",
    "# slicing up to order 5\n",
    "X_train_ord5 = X_train.iloc[:,:number_of_index]\n",
    "X_test_ord5 = X_test.iloc[:,:number_of_index]\n",
    "\n",
    "# print shape\n",
    "print(\"Train\", X_train_ord5.shape)\n",
    "print(\"Test\", X_test_ord5.shape)\n",
    "print()\n",
    "##########################################################\n",
    "n_order = 10 \n",
    "number_of_index = getOrderIndex(n_order) - 4\n",
    "print(number_of_index)\n",
    "\n",
    "# slicing up to order 10\n",
    "X_train_ord10 = X_train.iloc[:,:number_of_index]\n",
    "X_test_ord10 = X_test.iloc[:,:number_of_index]\n",
    "\n",
    "# print shape\n",
    "print(\"Train\", X_train_ord10.shape)\n",
    "print(\"Test\", X_test_ord10.shape)\n",
    "print()\n",
    "##########################################################\n",
    "\n",
    "n_order = 15\n",
    "number_of_index = getOrderIndex(n_order) - 4\n",
    "print(number_of_index)\n",
    "\n",
    "# slicing up to order 15\n",
    "X_train_ord15 = X_train.iloc[:,:number_of_index]\n",
    "X_test_ord15 = X_test.iloc[:,:number_of_index]\n",
    "\n",
    "# print shape\n",
    "print(\"Train\", X_train_ord15.shape)\n",
    "print(\"Test\", X_test_ord15.shape)\n",
    "print()\n",
    "##########################################################\n",
    "\n",
    "n_order = 20\n",
    "number_of_index = getOrderIndex(n_order) - 4\n",
    "print(number_of_index)\n",
    "\n",
    "# slicing up to order 20\n",
    "X_train_ord20 = X_train.iloc[:,:number_of_index]\n",
    "X_test_ord20 = X_test.iloc[:,:number_of_index]\n",
    "\n",
    "# print shape\n",
    "print(\"Train\", X_train_ord20.shape)\n",
    "print(\"Test\", X_test_ord20.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "39a3b381",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainsets = [\n",
    "    X_train_ord5, X_train_ord10, X_train_ord15, X_train_ord20\n",
    "]\n",
    "\n",
    "testsets = [\n",
    "    X_test_ord5, X_test_ord10, X_test_ord15, X_test_ord20\n",
    "] \n",
    "\n",
    "featureSelectionMethods = [\n",
    "    \"ord = 5\", \"ord = 10\", \"ord = 15\", \"ord = 20\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf144f9",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "76ad1315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Model\n",
    "def modelTraining(model):\n",
    "    for train, test, fSMethod in zip(trainsets, testsets, featureSelectionMethods):\n",
    "        print(f\"Feature Selection with {fSMethod}\")\n",
    "        model = model.fit(train, y_train)\n",
    "\n",
    "        summary = PrettyTable()\n",
    "        summary.field_names = [\"Score (%)\"]\n",
    "        summary.add_row([round(model.score(test, y_test) * 100, 2)])\n",
    "        print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5107a602",
   "metadata": {},
   "source": [
    "### Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2aedba98",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Selection with ord = 5\n",
      "+-----------+\n",
      "| Score (%) |\n",
      "+-----------+\n",
      "|   60.79   |\n",
      "+-----------+\n",
      "Feature Selection with ord = 10\n",
      "+-----------+\n",
      "| Score (%) |\n",
      "+-----------+\n",
      "|   60.79   |\n",
      "+-----------+\n",
      "Feature Selection with ord = 15\n",
      "+-----------+\n",
      "| Score (%) |\n",
      "+-----------+\n",
      "|   60.79   |\n",
      "+-----------+\n",
      "Feature Selection with ord = 20\n",
      "+-----------+\n",
      "| Score (%) |\n",
      "+-----------+\n",
      "|   60.79   |\n",
      "+-----------+\n"
     ]
    }
   ],
   "source": [
    "model = SVC()\n",
    "modelTraining(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a2fc01",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fd6a9821",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Selection with ord = 5\n",
      "+-----------+\n",
      "| Score (%) |\n",
      "+-----------+\n",
      "|   60.75   |\n",
      "+-----------+\n",
      "Feature Selection with ord = 10\n",
      "+-----------+\n",
      "| Score (%) |\n",
      "+-----------+\n",
      "|   60.81   |\n",
      "+-----------+\n",
      "Feature Selection with ord = 15\n",
      "+-----------+\n",
      "| Score (%) |\n",
      "+-----------+\n",
      "|   60.81   |\n",
      "+-----------+\n",
      "Feature Selection with ord = 20\n",
      "+-----------+\n",
      "| Score (%) |\n",
      "+-----------+\n",
      "|   60.81   |\n",
      "+-----------+\n"
     ]
    }
   ],
   "source": [
    "model = KNeighborsClassifier(30)\n",
    "modelTraining(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63bc32d",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "422872a3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Selection with ord = 5\n",
      "+-----------+\n",
      "| Score (%) |\n",
      "+-----------+\n",
      "|   60.62   |\n",
      "+-----------+\n",
      "Feature Selection with ord = 10\n",
      "+-----------+\n",
      "| Score (%) |\n",
      "+-----------+\n",
      "|   60.83   |\n",
      "+-----------+\n",
      "Feature Selection with ord = 15\n",
      "+-----------+\n",
      "| Score (%) |\n",
      "+-----------+\n",
      "|    60.9   |\n",
      "+-----------+\n",
      "Feature Selection with ord = 20\n",
      "+-----------+\n",
      "| Score (%) |\n",
      "+-----------+\n",
      "|   60.73   |\n",
      "+-----------+\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(criterion = 'entropy', max_depth = 4, splitter = 'best')\n",
    "modelTraining(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9b6517",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0914bdca",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Selection with ord = 5\n",
      "+-----------+\n",
      "| Score (%) |\n",
      "+-----------+\n",
      "|   60.81   |\n",
      "+-----------+\n",
      "Feature Selection with ord = 10\n",
      "+-----------+\n",
      "| Score (%) |\n",
      "+-----------+\n",
      "|   60.83   |\n",
      "+-----------+\n",
      "Feature Selection with ord = 15\n",
      "+-----------+\n",
      "| Score (%) |\n",
      "+-----------+\n",
      "|   60.83   |\n",
      "+-----------+\n",
      "Feature Selection with ord = 20\n",
      "+-----------+\n",
      "| Score (%) |\n",
      "+-----------+\n",
      "|   60.79   |\n",
      "+-----------+\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(max_depth = 6, random_state = 10)\n",
    "modelTraining(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607538da",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "05f007a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14977,)\n",
      "(6420,)\n"
     ]
    }
   ],
   "source": [
    "# convert the labels from integers to one-hot-encoded vectors\n",
    "lb = LabelEncoder()\n",
    "y_train = lb.fit_transform(y_train)\n",
    "y_test = lb.transform(y_test)\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7d74bb99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14977, 5)\n",
      "(6420, 5)\n"
     ]
    }
   ],
   "source": [
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes = 5)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes = 5)\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5cdc7c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor = 'val_accuracy', mode = 'max', min_delta = 0.01,\n",
    "                                                                                    patience = 3, factor = 0.25, verbose = 1, cooldown = 0, min_lr = 0.0001)\n",
    "\n",
    "early_stopper = tf.keras.callbacks.EarlyStopping(monitor = 'val_accuracy', mode = 'max', min_delta = 0.005,\n",
    "                                                                                 patience = 10, verbose = 1, restore_best_weights = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ea1a46cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Selection with ord = 5\n",
      "Epoch 1/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 1.1868 - accuracy: 0.6162 - val_loss: 1.1995 - val_accuracy: 0.6079 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 1.1818 - accuracy: 0.6179 - val_loss: 1.1932 - val_accuracy: 0.6079 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 1.1794 - accuracy: 0.6179 - val_loss: 1.1909 - val_accuracy: 0.6079 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "444/469 [===========================>..] - ETA: 0s - loss: 1.1761 - accuracy: 0.6192\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 1.1789 - accuracy: 0.6179 - val_loss: 1.1945 - val_accuracy: 0.6079 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 1.1755 - accuracy: 0.6179 - val_loss: 1.1914 - val_accuracy: 0.6079 - lr: 2.5000e-04\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 1.1736 - accuracy: 0.6179 - val_loss: 1.1909 - val_accuracy: 0.6079 - lr: 2.5000e-04\n",
      "Epoch 7/20\n",
      "454/469 [============================>.] - ETA: 0s - loss: 1.1761 - accuracy: 0.6166\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 1.1736 - accuracy: 0.6179 - val_loss: 1.1909 - val_accuracy: 0.6079 - lr: 2.5000e-04\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 1.1718 - accuracy: 0.6180 - val_loss: 1.1901 - val_accuracy: 0.6079 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 1.1733 - accuracy: 0.6180 - val_loss: 1.1897 - val_accuracy: 0.6079 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 1.1734 - accuracy: 0.6180 - val_loss: 1.1896 - val_accuracy: 0.6079 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "450/469 [===========================>..] - ETA: 0s - loss: 1.1749 - accuracy: 0.6176Restoring model weights from the end of the best epoch: 1.\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 1.1736 - accuracy: 0.6180 - val_loss: 1.1900 - val_accuracy: 0.6079 - lr: 1.0000e-04\n",
      "Epoch 11: early stopping\n",
      "201/201 [==============================] - 0s 931us/step - loss: 1.1995 - accuracy: 0.6079\n",
      "Test accuracy: 0.6079439520835876\n",
      "\n",
      "\n",
      "Feature Selection with ord = 10\n",
      "Epoch 1/20\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 1.1943 - accuracy: 0.6167 - val_loss: 1.1931 - val_accuracy: 0.6079 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 1.1842 - accuracy: 0.6179 - val_loss: 1.1920 - val_accuracy: 0.6079 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 1.1797 - accuracy: 0.6179 - val_loss: 1.1887 - val_accuracy: 0.6079 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "461/469 [============================>.] - ETA: 0s - loss: 1.1812 - accuracy: 0.6184\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 1.1818 - accuracy: 0.6179 - val_loss: 1.1970 - val_accuracy: 0.6079 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 1.1750 - accuracy: 0.6179 - val_loss: 1.1863 - val_accuracy: 0.6079 - lr: 2.5000e-04\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 1.1723 - accuracy: 0.6179 - val_loss: 1.1863 - val_accuracy: 0.6079 - lr: 2.5000e-04\n",
      "Epoch 7/20\n",
      "448/469 [===========================>..] - ETA: 0s - loss: 1.1677 - accuracy: 0.6194\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 1.1701 - accuracy: 0.6179 - val_loss: 1.1863 - val_accuracy: 0.6079 - lr: 2.5000e-04\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 1.1714 - accuracy: 0.6179 - val_loss: 1.1843 - val_accuracy: 0.6079 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 1.1682 - accuracy: 0.6179 - val_loss: 1.1842 - val_accuracy: 0.6079 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 1.1698 - accuracy: 0.6179 - val_loss: 1.1839 - val_accuracy: 0.6079 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "453/469 [===========================>..] - ETA: 0s - loss: 1.1702 - accuracy: 0.6175Restoring model weights from the end of the best epoch: 1.\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 1.1692 - accuracy: 0.6179 - val_loss: 1.1837 - val_accuracy: 0.6079 - lr: 1.0000e-04\n",
      "Epoch 11: early stopping\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 1.1931 - accuracy: 0.6079\n",
      "Test accuracy: 0.6079439520835876\n",
      "\n",
      "\n",
      "Feature Selection with ord = 15\n",
      "Epoch 1/20\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 1.1971 - accuracy: 0.6173 - val_loss: 1.1896 - val_accuracy: 0.6079 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 1.1825 - accuracy: 0.6179 - val_loss: 1.1878 - val_accuracy: 0.6079 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 1.1815 - accuracy: 0.6179 - val_loss: 1.1930 - val_accuracy: 0.6079 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "460/469 [============================>.] - ETA: 0s - loss: 1.1792 - accuracy: 0.6173\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 1.1782 - accuracy: 0.6179 - val_loss: 1.1960 - val_accuracy: 0.6079 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 1.1737 - accuracy: 0.6179 - val_loss: 1.1830 - val_accuracy: 0.6079 - lr: 2.5000e-04\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 1.1726 - accuracy: 0.6179 - val_loss: 1.1810 - val_accuracy: 0.6079 - lr: 2.5000e-04\n",
      "Epoch 7/20\n",
      "466/469 [============================>.] - ETA: 0s - loss: 1.1735 - accuracy: 0.6178\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 1.1731 - accuracy: 0.6179 - val_loss: 1.1794 - val_accuracy: 0.6079 - lr: 2.5000e-04\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 1.1691 - accuracy: 0.6179 - val_loss: 1.1789 - val_accuracy: 0.6079 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 1.1676 - accuracy: 0.6179 - val_loss: 1.1787 - val_accuracy: 0.6079 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 1.1695 - accuracy: 0.6179 - val_loss: 1.1785 - val_accuracy: 0.6079 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "462/469 [============================>.] - ETA: 0s - loss: 1.1697 - accuracy: 0.6180Restoring model weights from the end of the best epoch: 1.\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 1.1693 - accuracy: 0.6179 - val_loss: 1.1784 - val_accuracy: 0.6079 - lr: 1.0000e-04\n",
      "Epoch 11: early stopping\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 1.1896 - accuracy: 0.6079\n",
      "Test accuracy: 0.6079439520835876\n",
      "\n",
      "\n",
      "Feature Selection with ord = 20\n",
      "Epoch 1/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 1.2106 - accuracy: 0.6170 - val_loss: 1.2004 - val_accuracy: 0.6079 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 1.1906 - accuracy: 0.6179 - val_loss: 1.1927 - val_accuracy: 0.6079 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 1.1893 - accuracy: 0.6179 - val_loss: 1.1917 - val_accuracy: 0.6079 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "464/469 [============================>.] - ETA: 0s - loss: 1.1810 - accuracy: 0.6184\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 1.1820 - accuracy: 0.6179 - val_loss: 1.1943 - val_accuracy: 0.6079 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 1.1752 - accuracy: 0.6179 - val_loss: 1.1824 - val_accuracy: 0.6079 - lr: 2.5000e-04\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 1.1723 - accuracy: 0.6179 - val_loss: 1.1829 - val_accuracy: 0.6079 - lr: 2.5000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20\n",
      "464/469 [============================>.] - ETA: 0s - loss: 1.1741 - accuracy: 0.6173\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 1.1728 - accuracy: 0.6179 - val_loss: 1.1808 - val_accuracy: 0.6079 - lr: 2.5000e-04\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 1.1695 - accuracy: 0.6179 - val_loss: 1.1805 - val_accuracy: 0.6079 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 1.1694 - accuracy: 0.6179 - val_loss: 1.1807 - val_accuracy: 0.6079 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 1.1683 - accuracy: 0.6179 - val_loss: 1.1801 - val_accuracy: 0.6079 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "458/469 [============================>.] - ETA: 0s - loss: 1.1694 - accuracy: 0.6180Restoring model weights from the end of the best epoch: 1.\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 1.1694 - accuracy: 0.6179 - val_loss: 1.1797 - val_accuracy: 0.6079 - lr: 1.0000e-04\n",
      "Epoch 11: early stopping\n",
      "201/201 [==============================] - 0s 1ms/step - loss: 1.2004 - accuracy: 0.6079\n",
      "Test accuracy: 0.6079439520835876\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, train_set in enumerate(trainsets):\n",
    "    input_shape = train_set.shape[1]\n",
    "    test_set = testsets[i]\n",
    "    fSMethod = featureSelectionMethods[i]\n",
    "\n",
    "    print(f\"Feature Selection with {fSMethod}\")\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1024, input_shape = (input_shape,), activation = \"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(5, activation = \"softmax\"))\n",
    "\n",
    "    model.compile(optimizer = Adam(learning_rate = 0.001), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    model.fit(train_set, y_train, validation_data = (test_set, y_test), epochs = 20, callbacks = [early_stopper, reduce_lr])\n",
    "\n",
    "    score = model.evaluate(test_set, y_test, verbose = 1)\n",
    "    print('Test accuracy:', score[1])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bc3e65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
